<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">



<title>Web安全之机器学习入门-第5章-K近邻算法 | langke Blog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    



    
    
        
    


</head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">langke&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                

            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">langke&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div id="post-toc" class="post-toc">
            <span class="post-toc-title">catalogue</span>
            <div class="post-toc-content">
                <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#第5章-K近邻算法"><span class="toc-text">第5章 K近邻算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K近邻算法概述"><span class="toc-text">K近邻算法概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：Hello-world-K近邻"><span class="toc-text">示例：Hello world! K近邻</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#无监督学习"><span class="toc-text">无监督学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KNN用于监督学习"><span class="toc-text">KNN用于监督学习</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：-使用K近邻算法检测异常操作（一）"><span class="toc-text">示例： 使用K近邻算法检测异常操作（一）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-数据搜集和数据清洗"><span class="toc-text">1. 数据搜集和数据清洗</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-特征化"><span class="toc-text">2. 特征化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-训练模型"><span class="toc-text">3. 训练模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-效果验证"><span class="toc-text">4. 效果验证</span></a></li></ol></li></ol></li></ol>
            </div>
        </div>
    
    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Web安全之机器学习入门-第5章-K近邻算法</h1>
            
                <div class="post-meta">
                    

                    
                        <span class="post-time">
                        Date: <a href="#">12 11&nbsp;&nbsp;18:44:15</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <section class="post-content">
            <h2 id="第5章-K近邻算法"><a href="#第5章-K近邻算法" class="headerlink" title="第5章 K近邻算法"></a>第5章 K近邻算法</h2><h3 id="K近邻算法概述"><a href="#K近邻算法概述" class="headerlink" title="K近邻算法概述"></a>K近邻算法概述</h3><p>K近邻（K-Nearest Neighbor, KNN）算法是机器学习领域使用最广泛的算法之一，所谓KNN，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻居来代表。KNN算法的核心思想是：如果一个样本在特征空间中的K个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。<br>该方法在确定分类决策时，只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。KNN方法在类别决策时，只与极少量的相邻样本有关。由于KNN 方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别，因此对于类域交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为合适。</p>
<p>KNN 常用的算法为：</p>
<ul>
<li>Brute Force；</li>
<li>K-D Tree；</li>
<li>Ball Tree。</li>
</ul>
<h3 id="示例：Hello-world-K近邻"><a href="#示例：Hello-world-K近邻" class="headerlink" title="示例：Hello world! K近邻"></a>示例：Hello world! K近邻</h3><h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NearestNeighbors 实现了无监督的最近邻学习，</span></span><br><span class="line"><span class="comment"># 它为三种不同的学习算法（Ball-Tree，KD-Tree，sklearn.metrics.pairwise.brute-force）</span></span><br><span class="line"><span class="comment"># 参数`n_neighbors`用来指定K-NN里面的K（邻居）的数量</span></span><br><span class="line"><span class="comment"># 参数`algorithm`来控制使用哪种算法，取值`['auto', 'ball_tree', 'kd_tree', 'brute']`其中的一个，其中`auto`会根据给定的测试数据选择最终性能最好的一个算法。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">-1</span>, <span class="number">-1</span>], [<span class="number">-2</span>, <span class="number">-1</span>], [<span class="number">-3</span>, <span class="number">-2</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit()：训练算法，设置内部参数。接收训练集和类别两个参数。简单来说，就是求得训练集X的均值啊，方差啊，最大值啊，最小值啊这些训练集X固有的属性。可以理解为一个训练过程</span></span><br><span class="line">nbrs = NearestNeighbors(n_neighbors=<span class="number">2</span>, algorithm=<span class="string">'ball_tree'</span>).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 官网：https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighbors#sklearn.neighbors.KNeighborsClassifier</span></span><br><span class="line"><span class="comment"># kneighbors(self, X=None, n_neighbors=None, return_distance=True) 查找点的K邻居。返回每个点的邻居的索引和与之的距离。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># X：类似数组，形状为（n_queries，n_features），或者为（n_queries，n_indexed）</span></span><br><span class="line"><span class="comment"># n_neighbors int型 要获取的邻居数（默认值为传递给构造函数的值）。</span></span><br><span class="line"><span class="comment"># return_distance 布尔值，可选。默认为True。如果为False，则不会返回距离</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># distances 距离 </span></span><br><span class="line"><span class="comment"># indices 索引</span></span><br><span class="line">distances, indices = nbrs.kneighbors(X)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (indices)</span><br><span class="line"><span class="keyword">print</span> (distances)</span><br><span class="line"><span class="comment"># kneighbors_graph(self，X=None，n_neighbors=None，mode='connectivity') 计算X中点的k邻居的（加权）图</span></span><br><span class="line"><span class="keyword">print</span> (nbrs.kneighbors_graph(X).toarray())</span><br></pre></td></tr></table></figure>
<h4 id="KNN用于监督学习"><a href="#KNN用于监督学习" class="headerlink" title="KNN用于监督学习"></a>KNN用于监督学习</h4><p><a href="https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier" target="_blank" rel="noopener">KNeighborsClassifier官方文档</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNeighborsClassifier() 分类器执行k最近邻居投票。</span></span><br><span class="line"><span class="comment"># KNeighborsClassifier(n_neighbors=5,weights='uniform',algorithm='auto',leaf_size=30,p=2,metric='minkowski',metric_params=None,n_jobs=None,**kwargs)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">neigh.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict(self, X) 预测提供的数据（此处指X，数组）的类标签。</span></span><br><span class="line"><span class="comment"># predict_proba(self, X) 测试数据X的返回概率估计。</span></span><br><span class="line"></span><br><span class="line">print(neigh.predict([[<span class="number">1.1</span>]]))</span><br><span class="line">print(neigh.predict_proba([[<span class="number">0.9</span>]]))</span><br></pre></td></tr></table></figure></p>
<h3 id="示例：-使用K近邻算法检测异常操作（一）"><a href="#示例：-使用K近邻算法检测异常操作（一）" class="headerlink" title="示例： 使用K近邻算法检测异常操作（一）"></a>示例： 使用K近邻算法检测异常操作（一）</h3><h4 id="1-数据搜集和数据清洗"><a href="#1-数据搜集和数据清洗" class="headerlink" title="1. 数据搜集和数据清洗"></a>1. 数据搜集和数据清洗</h4><p>数据源：<a href="http://www.schonlau.net/" target="_blank" rel="noopener">http://www.schonlau.net/</a><br>数据共50个txt，当作50个用户的命令。每个用户采集15000个命令，一行一个。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">dist = []</span><br><span class="line"><span class="comment"># 依次读取每行操作命令， 每100个命令组成一个操作序列， 保存在列表里面</span></span><br><span class="line"><span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    x = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        line=line.strip(<span class="string">"\n"</span>)</span><br><span class="line">        x.append(line)</span><br><span class="line">        dist.append(line)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">100</span>：</span><br><span class="line">            cmd_list.append(x)</span><br><span class="line">            x = []</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计最频繁使用的前 50 个命令和最不频繁的前 50 个命令</span></span><br><span class="line"><span class="comment"># FreqDist继承自dict，所以可以像操作字典一样操作FreqDist对象。</span></span><br><span class="line"><span class="comment"># 本例中，FreqDist中的键为命令，值为命令出现的总次数。</span></span><br><span class="line"><span class="keyword">from</span> nltk.probability <span class="keyword">import</span> FreqDist</span><br><span class="line">fdist = FreqDist(dist).keys()</span><br><span class="line">dist_max = set(fdist[:<span class="number">50</span>])</span><br><span class="line">dist_min = set(fdist[<span class="number">-50</span>:])</span><br></pre></td></tr></table></figure>
<h4 id="2-特征化"><a href="#2-特征化" class="headerlink" title="2. 特征化"></a>2. 特征化</h4><p>（1）去重操作命令的个数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cmd_block 100个一组的命令列表，去重后的操作命令的个数作为特征</span></span><br><span class="line">f1 = len(set(cmd_block))</span><br></pre></td></tr></table></figure></p>
<p>（2）最频繁使用的前10个命令。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 频繁使用从某种程度上反映出当前用户的操作习惯</span></span><br><span class="line">fdist = list(FreqDist(cmd_block).keys())</span><br><span class="line">f2 = fdist[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure></p>
<p>（3）最不频繁使用的前10个命令<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最不频繁使用的命令也从某种程度上反映出当前用户的使用习惯。</span></span><br><span class="line">f3 = fdist[<span class="number">-10</span>:]</span><br></pre></td></tr></table></figure></p>
<p>KNN只能以标量作为输入参数，所以需要将f2和f3标量化，最简单的方式就是和统计的最频繁使用的前50个命令以及最不频繁使用的前50个命令计算重合度<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f2 = len(set(f2) &amp; set(dist_max))</span><br><span class="line">f3 = len(set(f3) &amp; set(dist_min))</span><br></pre></td></tr></table></figure></p>
<h4 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3. 训练模型"></a>3. 训练模型</h4><p>标识文件内容： 每行50列，分别代表每个用户的当前操作序列，正常操作标识为0，异常操作标识为1.<br>从标识文件中加载针对操作序列正常和异常的标识：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_label</span><span class="params">(filename, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            line = line.strip()</span><br><span class="line">            x.append(int(line.split()[index]))</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>加载user3的操作数据，并将前90个操作序列作为训练序列，后60个操作序列作为测试序列。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">user_cmd_list, user_cmd_dist_max, user_cmd_dist_min = load_user_cmd(<span class="string">"../../User3"</span>)</span><br><span class="line">user_cmd_feature = get_user_cmd_feature(user_cmd_list, user_cmd_dist_max, user_cmd_dist_min)</span><br><span class="line">labels = get_label(<span class="string">"../../label.txt"</span>, <span class="number">2</span>)</span><br><span class="line">y = [<span class="number">0</span>]*<span class="number">50</span>+labels</span><br><span class="line">x_train = user_cmd_feature[:N]</span><br><span class="line">y_train = y[:N]</span><br><span class="line">x_test = user_cmd_feature[N:<span class="number">150</span>]</span><br><span class="line">y_test = y[N:<span class="number">150</span>]</span><br></pre></td></tr></table></figure></p>
<p>调用 KNN 函数进行训练<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">neigh.fit(x_train, y_train)</span><br><span class="line">y_predict = neigh.predict(x_test)</span><br></pre></td></tr></table></figure></p>
<h4 id="4-效果验证"><a href="#4-效果验证" class="headerlink" title="4. 效果验证"></a>4. 效果验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score = np.mean(y_test==y_predict)*<span class="number">100</span></span><br></pre></td></tr></table></figure>
        </section>

        
            <section class="post-copyright">
                
                
                
                

            </section>
        

        <!--
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/web安全之机器学习/"># web安全之机器学习</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        -->
        <!--
        <section class="post-nav">
            
            
            <a class="next" rel="next" href="/2019/12/10/Web安全之机器学习入门-第3章-机器学习概述/">Web安全之机器学习入门-第3章-机器学习概述</a>
            
        </section>
        -->

    </article>
</div>

        </div>
        <!--
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© langke | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    	-->

    	<br>
    	<br>
    	<br>



    </div>
</body>
</html>
