<!DOCTYPE html>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">



<title>Web安全之机器学习入门-第5章-K近邻算法 | langke Blog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    



    
    
        
    


</head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">langke&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                

            </div>

        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">langke&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div id="post-toc" class="post-toc">
            <span class="post-toc-title">catalogue</span>
            <div class="post-toc-content">
                <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#第5章-K近邻算法"><span class="toc-text">第5章 K近邻算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K近邻算法概述"><span class="toc-text">K近邻算法概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：Hello-world-K近邻"><span class="toc-text">示例：Hello world! K近邻</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#无监督学习"><span class="toc-text">无监督学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KNN用于监督学习"><span class="toc-text">KNN用于监督学习</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：-使用K近邻算法检测异常操作（一）"><span class="toc-text">示例： 使用K近邻算法检测异常操作（一）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-数据搜集和数据清洗"><span class="toc-text">1. 数据搜集和数据清洗</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-特征化"><span class="toc-text">2. 特征化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-训练模型"><span class="toc-text">3. 训练模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-效果验证"><span class="toc-text">4. 效果验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：使用K近邻算法检测异常操作（二）"><span class="toc-text">示例：使用K近邻算法检测异常操作（二）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-数据搜集和数据清洗-1"><span class="toc-text">1. 数据搜集和数据清洗</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-特征化-1"><span class="toc-text">2. 特征化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-训练模型-1"><span class="toc-text">3. 训练模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-效果验证-1"><span class="toc-text">4. 效果验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：-使用K近邻算法检测Rootkit"><span class="toc-text">示例： 使用K近邻算法检测Rootkit</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-数据搜集和数据清洗-2"><span class="toc-text">1. 数据搜集和数据清洗</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-特征化-2"><span class="toc-text">2. 特征化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-训练样本"><span class="toc-text">3. 训练样本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-效果验证-2"><span class="toc-text">4. 效果验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：-使用K近邻算法检测WebShell"><span class="toc-text">示例： 使用K近邻算法检测WebShell</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-数据搜集和数据清洗-3"><span class="toc-text">1. 数据搜集和数据清洗</span></a></li></ol></li></ol></li></ol>
            </div>
        </div>
    
    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Web安全之机器学习入门-第5章-K近邻算法</h1>
            
                <div class="post-meta">
                    

                    
                        <span class="post-time">
                        Date: <a href="#">12 11&nbsp;&nbsp;18:44:15</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <section class="post-content">
            <h2 id="第5章-K近邻算法"><a href="#第5章-K近邻算法" class="headerlink" title="第5章 K近邻算法"></a>第5章 K近邻算法</h2><h3 id="K近邻算法概述"><a href="#K近邻算法概述" class="headerlink" title="K近邻算法概述"></a>K近邻算法概述</h3><p>K近邻（K-Nearest Neighbor, KNN）算法是机器学习领域使用最广泛的算法之一，所谓KNN，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻居来代表。KNN算法的核心思想是：如果一个样本在特征空间中的K个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。<br>该方法在确定分类决策时，只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。KNN方法在类别决策时，只与极少量的相邻样本有关。由于KNN 方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别，因此对于类域交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为合适。</p>
<p>KNN 常用的算法为：</p>
<ul>
<li>Brute Force；</li>
<li>K-D Tree；</li>
<li>Ball Tree。</li>
</ul>
<h3 id="示例：Hello-world-K近邻"><a href="#示例：Hello-world-K近邻" class="headerlink" title="示例：Hello world! K近邻"></a>示例：Hello world! K近邻</h3><h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NearestNeighbors 实现了无监督的最近邻学习，</span></span><br><span class="line"><span class="comment"># 它为三种不同的学习算法（Ball-Tree，KD-Tree，sklearn.metrics.pairwise.brute-force）</span></span><br><span class="line"><span class="comment"># 参数`n_neighbors`用来指定K-NN里面的K（邻居）的数量</span></span><br><span class="line"><span class="comment"># 参数`algorithm`来控制使用哪种算法，取值`['auto', 'ball_tree', 'kd_tree', 'brute']`其中的一个，其中`auto`会根据给定的测试数据选择最终性能最好的一个算法。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">-1</span>, <span class="number">-1</span>], [<span class="number">-2</span>, <span class="number">-1</span>], [<span class="number">-3</span>, <span class="number">-2</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit()：训练算法，设置内部参数。接收训练集和类别两个参数。简单来说，就是求得训练集X的均值啊，方差啊，最大值啊，最小值啊这些训练集X固有的属性。可以理解为一个训练过程</span></span><br><span class="line">nbrs = NearestNeighbors(n_neighbors=<span class="number">2</span>, algorithm=<span class="string">'ball_tree'</span>).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 官网：https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighbors#sklearn.neighbors.KNeighborsClassifier</span></span><br><span class="line"><span class="comment"># kneighbors(self, X=None, n_neighbors=None, return_distance=True) 查找点的K邻居。返回每个点的邻居的索引和与之的距离。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># X：类似数组，形状为（n_queries，n_features），或者为（n_queries，n_indexed）</span></span><br><span class="line"><span class="comment"># n_neighbors int型 要获取的邻居数（默认值为传递给构造函数的值）。</span></span><br><span class="line"><span class="comment"># return_distance 布尔值，可选。默认为True。如果为False，则不会返回距离</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># distances 距离 </span></span><br><span class="line"><span class="comment"># indices 索引</span></span><br><span class="line">distances, indices = nbrs.kneighbors(X)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (indices)</span><br><span class="line"><span class="keyword">print</span> (distances)</span><br><span class="line"><span class="comment"># kneighbors_graph(self，X=None，n_neighbors=None，mode='connectivity') 计算X中点的k邻居的（加权）图</span></span><br><span class="line"><span class="keyword">print</span> (nbrs.kneighbors_graph(X).toarray())</span><br></pre></td></tr></table></figure>
<h4 id="KNN用于监督学习"><a href="#KNN用于监督学习" class="headerlink" title="KNN用于监督学习"></a>KNN用于监督学习</h4><p><a href="https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier" target="_blank" rel="noopener">KNeighborsClassifier官方文档</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNeighborsClassifier() 分类器执行k最近邻居投票。</span></span><br><span class="line"><span class="comment"># KNeighborsClassifier(n_neighbors=5,weights='uniform',algorithm='auto',leaf_size=30,p=2,metric='minkowski',metric_params=None,n_jobs=None,**kwargs)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">x = [[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">neigh.fit(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict(self, X) 预测提供的数据（此处指X，数组）的类标签。</span></span><br><span class="line"><span class="comment"># predict_proba(self, X) 测试数据X的返回概率估计。</span></span><br><span class="line"></span><br><span class="line">print(neigh.predict([[<span class="number">1.1</span>]]))</span><br><span class="line">print(neigh.predict_proba([[<span class="number">0.9</span>]]))</span><br></pre></td></tr></table></figure></p>
<h3 id="示例：-使用K近邻算法检测异常操作（一）"><a href="#示例：-使用K近邻算法检测异常操作（一）" class="headerlink" title="示例： 使用K近邻算法检测异常操作（一）"></a>示例： 使用K近邻算法检测异常操作（一）</h3><h4 id="1-数据搜集和数据清洗"><a href="#1-数据搜集和数据清洗" class="headerlink" title="1. 数据搜集和数据清洗"></a>1. 数据搜集和数据清洗</h4><p>数据源：<a href="http://www.schonlau.net/" target="_blank" rel="noopener">http://www.schonlau.net/</a><br>数据共50个txt，当作50个用户的命令。每个用户采集15000个命令，一行一个。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">dist = []</span><br><span class="line"><span class="comment"># 依次读取每行操作命令， 每100个命令组成一个操作序列， 保存在列表里面</span></span><br><span class="line"><span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    x = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        line=line.strip(<span class="string">"\n"</span>)</span><br><span class="line">        x.append(line)</span><br><span class="line">        dist.append(line)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">100</span>：</span><br><span class="line">            cmd_list.append(x)</span><br><span class="line">            x = []</span><br><span class="line">            i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计最频繁使用的前 50 个命令和最不频繁的前 50 个命令</span></span><br><span class="line"><span class="comment"># FreqDist继承自dict，所以可以像操作字典一样操作FreqDist对象。</span></span><br><span class="line"><span class="comment"># 本例中，FreqDist中的键为命令，值为命令出现的总次数。</span></span><br><span class="line"><span class="keyword">from</span> nltk.probability <span class="keyword">import</span> FreqDist</span><br><span class="line">fdist = FreqDist(dist).keys()</span><br><span class="line">dist_max = set(fdist[:<span class="number">50</span>])</span><br><span class="line">dist_min = set(fdist[<span class="number">-50</span>:])</span><br></pre></td></tr></table></figure>
<h4 id="2-特征化"><a href="#2-特征化" class="headerlink" title="2. 特征化"></a>2. 特征化</h4><p>（1）去重操作命令的个数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cmd_block 100个一组的命令列表，去重后的操作命令的个数作为特征</span></span><br><span class="line">f1 = len(set(cmd_block))</span><br></pre></td></tr></table></figure></p>
<p>（2）最频繁使用的前10个命令。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 频繁使用从某种程度上反映出当前用户的操作习惯</span></span><br><span class="line">fdist = list(FreqDist(cmd_block).keys())</span><br><span class="line">f2 = fdist[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure></p>
<p>（3）最不频繁使用的前10个命令<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最不频繁使用的命令也从某种程度上反映出当前用户的使用习惯。</span></span><br><span class="line">f3 = fdist[<span class="number">-10</span>:]</span><br></pre></td></tr></table></figure></p>
<p>KNN只能以标量作为输入参数，所以需要将f2和f3标量化，最简单的方式就是和统计的最频繁使用的前50个命令以及最不频繁使用的前50个命令计算重合度<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f2 = len(set(f2) &amp; set(dist_max))</span><br><span class="line">f3 = len(set(f3) &amp; set(dist_min))</span><br></pre></td></tr></table></figure></p>
<h4 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3. 训练模型"></a>3. 训练模型</h4><p>标识文件内容： 每行50列，分别代表每个用户的当前操作序列，正常操作标识为0，异常操作标识为1.<br>从标识文件中加载针对操作序列正常和异常的标识：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_label</span><span class="params">(filename, index=<span class="number">0</span>)</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            line = line.strip()</span><br><span class="line">            x.append(int(line.split()[index]))</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>加载user3的操作数据，并将前90个操作序列作为训练序列，后60个操作序列作为测试序列。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">user_cmd_list, user_cmd_dist_max, user_cmd_dist_min = load_user_cmd(<span class="string">"../../User3"</span>)</span><br><span class="line">user_cmd_feature = get_user_cmd_feature(user_cmd_list, user_cmd_dist_max, user_cmd_dist_min)</span><br><span class="line">labels = get_label(<span class="string">"../../label.txt"</span>, <span class="number">2</span>)</span><br><span class="line">y = [<span class="number">0</span>]*<span class="number">50</span>+labels</span><br><span class="line">x_train = user_cmd_feature[:N]</span><br><span class="line">y_train = y[:N]</span><br><span class="line">x_test = user_cmd_feature[N:<span class="number">150</span>]</span><br><span class="line">y_test = y[N:<span class="number">150</span>]</span><br></pre></td></tr></table></figure></p>
<p>调用 KNN 函数进行训练<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">neigh.fit(x_train, y_train)</span><br><span class="line">y_predict = neigh.predict(x_test)</span><br></pre></td></tr></table></figure></p>
<h4 id="4-效果验证"><a href="#4-效果验证" class="headerlink" title="4. 效果验证"></a>4. 效果验证</h4><p><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html" target="_blank" rel="noopener">mean 官方文档</a><br>numpy.mean(a,axis=None,dtype=None,out=None,keepdims=&lt;无值&gt;)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score = np.mean(y_test==y_predict)*<span class="number">100</span></span><br></pre></td></tr></table></figure></p>
<h3 id="示例：使用K近邻算法检测异常操作（二）"><a href="#示例：使用K近邻算法检测异常操作（二）" class="headerlink" title="示例：使用K近邻算法检测异常操作（二）"></a>示例：使用K近邻算法检测异常操作（二）</h3><p>上例中只比较了最频繁和最不频繁的操作命令，下面进行全量比较。</p>
<h4 id="1-数据搜集和数据清洗-1"><a href="#1-数据搜集和数据清洗-1" class="headerlink" title="1. 数据搜集和数据清洗"></a>1. 数据搜集和数据清洗</h4><p>我们使用词集的模型，将全部命令去重后形成一个大型向量空间，每个命令代表一个特征，首先通过遍历全部命令，生成对应的词集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        line = line.strip(<span class="string">'\n'</span>)</span><br><span class="line">        dist.append(line)</span><br><span class="line"><span class="comment"># fdist 为去重后的命令列表</span></span><br><span class="line">fdist = FreqDist(dist).keys()</span><br></pre></td></tr></table></figure></p>
<h4 id="2-特征化-1"><a href="#2-特征化-1" class="headerlink" title="2. 特征化"></a>2. 特征化</h4><p>使用词集将操作命令向量化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_user_cmd_feature_new</span><span class="params">(user_cmd_list, dist)</span>:</span></span><br><span class="line">    user_cmd_feature = []</span><br><span class="line">    <span class="keyword">for</span> cmd_list <span class="keyword">in</span> user_cmd_list:</span><br><span class="line">        v = [<span class="number">0</span>] * len(dist)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(dist)):</span><br><span class="line">            <span class="keyword">if</span> dist[i] <span class="keyword">in</span> cmd_list:</span><br><span class="line">                v[i] += <span class="number">1</span></span><br><span class="line">        user_cmd_feature.append(v)</span><br><span class="line">    <span class="keyword">return</span> user_cmd_feature</span><br></pre></td></tr></table></figure>
<h4 id="3-训练模型-1"><a href="#3-训练模型-1" class="headerlink" title="3. 训练模型"></a>3. 训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">user_cmd_list, dist = load_user_cmd_new(<span class="string">"../data/MasqueradeDat/User3"</span>)</span><br><span class="line">user_cmd_feature = get_user_cmd_feature_new(user_cmd_list, dist)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">labels = get_label(<span class="string">"../data/MasqueradeDat/label.txt"</span>, <span class="number">2</span>)</span><br><span class="line">y = [<span class="number">0</span>] * <span class="number">50</span> + labels</span><br><span class="line">neigh = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h4 id="4-效果验证-1"><a href="#4-效果验证-1" class="headerlink" title="4. 效果验证"></a>4. 效果验证</h4><p>使用交叉验证， 10次随机取样和验证，提高验证可信度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># sklearn.model_selection.cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)</span></span><br><span class="line"><span class="comment"># 通过交叉验证评估分数</span></span><br><span class="line"><span class="comment"># neigh: 用于拟合数据的对象。</span></span><br><span class="line"><span class="comment"># user_cmd_feature: 要拟合的数据。例如可以是列表或数组</span></span><br><span class="line"><span class="comment"># y: 在监督学习的情况下要尝试预测的目标变量。</span></span><br><span class="line"><span class="comment"># n_jobs: 用于进行计算的CPU数量。 None除非joblib.parallel_backend上下文中，否则表示1 。 -1表示使用所有处理器。</span></span><br><span class="line"><span class="comment"># cv: 确定交叉验证拆分策略。</span></span><br><span class="line">model_selection.cross_val_score(neigh, user_cmd_feature, y, n_jobs=<span class="number">-1</span>, cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h3 id="示例：-使用K近邻算法检测Rootkit"><a href="#示例：-使用K近邻算法检测Rootkit" class="headerlink" title="示例： 使用K近邻算法检测Rootkit"></a>示例： 使用K近邻算法检测Rootkit</h3><p>Rootkit是一种特殊的恶意软件，它的功能是在安装目标上隐藏自身及指定的文件、进程和网络链接等信息，比较常见的是Rootkie，一般都和木马、后门等其他恶意程序结合使用。</p>
<h4 id="1-数据搜集和数据清洗-2"><a href="#1-数据搜集和数据清洗-2" class="headerlink" title="1. 数据搜集和数据清洗"></a>1. 数据搜集和数据清洗</h4><p>KDD 99数据已经完成了大部分的数据清洗工作，KDD 99数据集中每个连接用41个特征来描述：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">35,tcp,ftp,SF,96,533,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,221,3</span><br><span class="line">0,tcp,ftp_data,SF,116,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,0.00,25</span><br><span class="line">15,tcp,ftp,SF,45,214,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0.00,0.00,0.00,0.00,1.00,0.00,</span><br></pre></td></tr></table></figure></p>
<p><img src="https://image-langke.bj.bcebos.com/hexo-neirongpeitu/学习笔记/与Rootkit相关特征.png" alt="基于telnet连接的Rootkit检测流程"><br><img src="https://image-langke.bj.bcebos.com/hexo-neirongpeitu/学习笔记/KDD 99 TCP连接内容特征.png" alt="KDD 99 TCP连接内容特征"></p>
<p>加载KDD 99数据集中的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_kdd99</span><span class="params">(filename)</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            line = line.strip()</span><br><span class="line">            line = line.split(<span class="string">','</span>)</span><br><span class="line">            x.append(line)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure></p>
<p>筛选标记为<code>Rootkit</code>和<code>normal</code>且是<code>telnet</code>协议的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (x1[<span class="number">41</span>] <span class="keyword">in</span> [<span class="string">'rootkit.'</span>,<span class="string">'normal.'</span>]) <span class="keyword">and</span> (x1[<span class="number">2</span>] == <span class="string">'telnet'</span>):</span><br><span class="line">    <span class="keyword">if</span> x1[<span class="number">41</span>] == <span class="string">'rootkit.'</span>:</span><br><span class="line">        y.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        y.append(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="2-特征化-2"><a href="#2-特征化-2" class="headerlink" title="2. 特征化"></a>2. 特征化</h4><p>挑选与Rootkit相关的特征作为样本特征：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x1 = x1[<span class="number">9</span>:<span class="number">21</span>]</span><br><span class="line">v.append(x1)</span><br><span class="line"><span class="keyword">for</span> x1 <span class="keyword">in</span> v:</span><br><span class="line">    v1 = []</span><br><span class="line">    <span class="keyword">for</span> x2 <span class="keyword">in</span> x1:</span><br><span class="line">        v1.append(float(x2))</span><br><span class="line">    w.append(v1)</span><br></pre></td></tr></table></figure></p>
<h4 id="3-训练样本"><a href="#3-训练样本" class="headerlink" title="3. 训练样本"></a>3. 训练样本</h4><p>实例化KNN算法，邻居数设置为3：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="4-效果验证-2"><a href="#4-效果验证-2" class="headerlink" title="4. 效果验证"></a>4. 效果验证</h4><p>我们使用十折交叉验证<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(model_selection.cross_val_score(clf, x, y, n_jobs=<span class="number">-1</span>, cv=<span class="number">10</span>))</span><br></pre></td></tr></table></figure></p>
<h3 id="示例：-使用K近邻算法检测WebShell"><a href="#示例：-使用K近邻算法检测WebShell" class="headerlink" title="示例： 使用K近邻算法检测WebShell"></a>示例： 使用K近邻算法检测WebShell</h3><h4 id="1-数据搜集和数据清洗-3"><a href="#1-数据搜集和数据清洗-3" class="headerlink" title="1. 数据搜集和数据清洗"></a>1. 数据搜集和数据清洗</h4><p>使用ADFA-LD 数据集中WebShell相关数据，ADFA-LD数据集中记录下了系统调用序列，比如（系统调用A、系统调用B、系统调用C），然后使用数字标识每一个系统调用，这样就转换成了系统调用序列（1，2，3），这时（1，2，3）就转换成了一个序列向量。</p>
<p>加载ADFA-LD中的正常样本数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_adfa_training_files</span><span class="params">(rootdir)</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    y = []</span><br><span class="line">    list = os.listdir(rootdir)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(list)):</span><br><span class="line">        path = os.path.join(rootdir, list[i])</span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(path):</span><br><span class="line">            x.append(load_one_file(path))</span><br><span class="line">            y.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure></p>
<p>定义遍历目录下文件的函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dirlist</span><span class="params">(path, allfile)</span>:</span></span><br><span class="line">    filelist = os.listdir(path)</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filelist:</span><br><span class="line">        filepath = os.path.join(path, filename)</span><br><span class="line">        <span class="keyword">if</span> os.path.isdir(filepath):</span><br><span class="line">            dirlist(filepath, allfile)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            allfile.append(filepath)</span><br><span class="line">    <span class="keyword">return</span> allfile</span><br></pre></td></tr></table></figure></p>
<p>从攻击数据集中筛选和WebShell相关的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_adfa_webshell_files</span><span class="params">(rootdir)</span>:</span></span><br><span class="line">    x = []</span><br><span class="line">    y = []</span><br><span class="line">    allfile = dirlist(rootdir, [])</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> allfile:</span><br><span class="line">        <span class="keyword">if</span> re.match(<span class="string">r"../data/ADFA-LD/Attack_Data_Master/Web_Shell_\d+/UAD-W*"</span>, file):</span><br><span class="line">            x.append(load_one_file(file))</span><br><span class="line">            y.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure></p>

        </section>

        
            <section class="post-copyright">
                
                
                
                

            </section>
        

        <!--
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/web安全之机器学习/"># web安全之机器学习</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        -->
        <!--
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2100/11/03/软件官网下载地址/">软件官网下载地址</a>
            
            
            <a class="next" rel="next" href="/2019/12/10/Web安全之机器学习入门-第3章-机器学习概述/">Web安全之机器学习入门-第3章-机器学习概述</a>
            
        </section>
        -->

    </article>
</div>

        </div>
        <!--
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© langke | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    	-->

    	<br>
    	<br>
    	<br>



    </div>
</body>
</html>
